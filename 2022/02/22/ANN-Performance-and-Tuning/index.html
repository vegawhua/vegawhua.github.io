<!DOCTYPE html><html lang="en"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content=""><title>ANN Performance and Tuning | Vega's Blog</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="/css/dark.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/normalize.css/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/purecss/build/pure-min.min.css"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/purecss/build/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.jsdelivr.net/npm/jquery/dist/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script type="text/javascript" src="//cdn.jsdelivr.net/npm/clipboard/dist/clipboard.min.js"></script><script type="text/javascript" src="//cdn.jsdelivr.net/gh/codeseven/toastr/build/toastr.min.js"></script><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/codeseven/toastr/build/toastr.min.css"><div class="darkmode-toggle">🌓</div><script>var prefersDarkMode = window.matchMedia('(prefers-color-scheme: dark)');
var toggle = document.querySelector('.darkmode-toggle');
var html = document.querySelector('html');

html.dataset.dark = localStorage.dark || prefersDarkMode.matches;

toggle.addEventListener('click', () => {
localStorage.dark = !(html.dataset.dark == 'true');
html.dataset.dark = localStorage.dark;
});</script><meta name="generator" content="Hexo 6.0.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">ANN Performance and Tuning</h1><a id="logo" href="/.">Vega's Blog</a><p class="description"></p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> Home</i></a><a href="/archives/"><i class="fa fa-archive"> Archive</i></a><a href="/about/"><i class="fa fa-user"> About</i></a><a href="/atom.xml"><i class="fa fa-rss"> RSS</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">ANN Performance and Tuning</h1><div class="post-meta">2022-02-22<span> | </span><span class="category"><a href="/categories/DL/">DL</a><a href="/categories/DL/ANN/">ANN</a></span></div><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">Contents</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Measure-K-fold-cross-validation"><span class="toc-number">1.</span> <span class="toc-text">Measure - K-fold cross-validation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Improve"><span class="toc-number">2.</span> <span class="toc-text">Improve</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Solving-Overfitting"><span class="toc-number">2.1.</span> <span class="toc-text">Solving Overfitting</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%A2%E5%BC%83%E6%AD%A3%E5%88%99%E5%8C%96%E6%B3%95-dropout-regularization"><span class="toc-number">2.1.1.</span> <span class="toc-text">丢弃正则化法 dropout regularization</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Parameter-Tuning"><span class="toc-number">2.2.</span> <span class="toc-text">Parameter Tuning</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Grid-Search-%E7%BD%91%E6%A0%BC%E6%90%9C%E7%B4%A2"><span class="toc-number">2.2.1.</span> <span class="toc-text">Grid Search 网格搜索</span></a></li></ol></li></ol></li></ol></div></div><div class="post-content"><p>引出：第一次epoch100次训练，accuracy是0.86，第二次的accuracy只有0.84了。</p>
<p>这说明accuracy并不是评估这个模型的最佳指标！</p>
<p>引入：方差权衡 bias-variance tradeoff</p>
<blockquote>
<p>当我们训练一个模型时，不仅要求准确率，训练多次时所得的多个准确率的方差要足够小</p>
</blockquote>
<p>仅仅用一个测试集数据的准确率来评估模型性能是不够的</p>
<p>更好的方法来衡量模型的性能 - <font color="red">K折交叉验证</font> k-fold cross-validation</p>
<h2 id="Measure-K-fold-cross-validation"><a href="#Measure-K-fold-cross-validation" class="headerlink" title="Measure - K-fold cross-validation"></a>Measure - K-fold cross-validation</h2><blockquote>
<p>Keras建的模型，k-fold在scikit-learn里，所以需要可以结合两者的包</p>
<p><code>from keras.wrappers.scikit_learn import KerasClassifier</code></p>
<p><code>from sklearn.model_selection import cross_val_score</code></p>
</blockquote>
<ol>
<li>定义一个<code>build_classifier</code>，重新建立ANN模型</li>
<li>使用<code>KerasClassifier</code>build分类器，定义<code>batch_size</code>和<code>epoch</code></li>
<li>设置新变量<code>accuracies</code>，将10个accuracy存储于其中</li>
<li>求<code>accuracies</code>平均值和方差</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.wrappers.scikit_learn <span class="keyword">import</span> KerasClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build_classifier</span> ():</span><br><span class="line">    </span><br><span class="line">    classifier = Sequential()</span><br><span class="line">    classifier.add(Dense(activation = <span class="string">&quot;relu&quot;</span>, units = <span class="number">6</span>, kernel_initializer = <span class="string">&quot;uniform&quot;</span>, input_dim = <span class="number">11</span>))</span><br><span class="line">    classifier.add(Dense(activation = <span class="string">&quot;relu&quot;</span>, units = <span class="number">6</span>, kernel_initializer = <span class="string">&quot;uniform&quot;</span>))</span><br><span class="line">    classifier.add(Dense(activation = <span class="string">&quot;sigmoid&quot;</span>, units = <span class="number">1</span>, kernel_initializer = <span class="string">&quot;uniform&quot;</span>))</span><br><span class="line">    classifier.<span class="built_in">compile</span>(optimizer = <span class="string">&quot;adam&quot;</span>, loss = <span class="string">&#x27;binary_crossentropy&#x27;</span>, metrics = [<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> classifier</span><br><span class="line"></span><br><span class="line">classifier = KerasClassifier(build_fn = build_classifier, batch_size = <span class="number">10</span>, nb_epoch = <span class="number">100</span>)</span><br><span class="line">accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = <span class="number">10</span>, n_jobs = -<span class="number">1</span>)</span><br><span class="line">mean = accuracies.mean()</span><br><span class="line">variance = accuracies.std()</span><br></pre></td></tr></table></figure>

<h2 id="Improve"><a href="#Improve" class="headerlink" title="Improve"></a>Improve</h2><p>引入：</p>
<blockquote>
<p>判断Overfitting: 模型用train set训练太多次，以至于它预测测试集的性能大幅降低，</p>
<ol>
<li><p><font color="red">训练集数据的准确率</font>和<font color="red">测试集数据的准确率</font>的<font color="red">巨大差异</font>来发现这个问题。</p>
<p>e.g. 训练集准确率 &gt;&gt; 测试集准确率</p>
</li>
<li><p>用<font color="red">K-fold cross-validation</font>的时候出现<font color="red">high variance</font>高方差</p>
</li>
</ol>
</blockquote>
<h3 id="Solving-Overfitting"><a href="#Solving-Overfitting" class="headerlink" title="Solving Overfitting"></a>Solving Overfitting</h3><h4 id="丢弃正则化法-dropout-regularization"><a href="#丢弃正则化法-dropout-regularization" class="headerlink" title="丢弃正则化法 dropout regularization"></a>丢弃正则化法 dropout regularization</h4><p><strong>原理：</strong></p>
<p>在train的每一次iteration中，ANN里的一些neurons will be banned randomly, 以预防neurons在学习数据间关系的时候变得互相过度依赖。通过覆盖这些neurons，NN可以学到数之间几种互不相关的关系：因为每一次iteration中，所用到的neurons和它们的distribution都不同。</p>
<p><strong>由于我们让各神经元更独立地计算，我们就可以得到数据中这些independent correlations</strong></p>
<blockquote>
<p>防止过度学习 –&gt; 防止overfitting</p>
</blockquote>
<p><strong>运行：</strong></p>
<ol>
<li><p><code>from keras.layers import Dropout</code></p>
</li>
<li><p>把<code>Dropout</code>应用于网络层上 - 如果有overfitting的情况，需要apply到所有层 - 更加有可能减少过拟合</p>
<blockquote>
<p>参数；</p>
<p><code>P</code>: 0-1，代表需要丢弃的neurons比例，建议先从0.1开始，如果应用后还是有过拟合问题，再逐步加大丢弃比例；如果到<font color="red">1</font>还是有过拟合问题，则代表是<font color="red">欠拟合underfitting</font>，这代表没有任何神经元可以用来学习任何东西；一般来讲<font color="red"><code>P</code>≤0.5</font>，就不会有underfitting的风险。</p>
</blockquote>
<p>如何改进模型的性能</p>
</li>
</ol>
<h3 id="Parameter-Tuning"><a href="#Parameter-Tuning" class="headerlink" title="Parameter Tuning"></a>Parameter Tuning</h3><ol>
<li><p>训练过程中模型学习到的参数（i.e. 权重）</p>
</li>
<li><p>保持不变的参数 - <font color="red">超参数 hyper parameters</font></p>
<p><code>batch_size</code>|  <code>epoch</code> &#x2F; <code>nb_epoch</code> | <code>optimizer</code></p>
<p>改动这些设置，会让交叉验证得到一个更好的准确率 - 找到这些超参数的<strong>最佳设置</strong></p>
</li>
</ol>
<h4 id="Grid-Search-网格搜索"><a href="#Grid-Search-网格搜索" class="headerlink" title="Grid Search 网格搜索"></a>Grid Search 网格搜索</h4><p>原理：测试超参数值的组合，并最终得到最佳组合</p>
<p>步骤：</p>
<ol>
<li>导入<code>GridSearchCV</code> class</li>
<li>构建build ANN的分类器函数，！需要给函数添加一个新参数，optimizer，需要调试它</li>
<li>建立ANN model，这次不需要epoch和batch_size，要grid search以后自动调出参数</li>
<li>建立一个dictionary，用来存储需要tune的超参数和它们的值</li>
<li>开始完成grid search，导入<code>GridSearchCV</code>class并给它建立一个对象<code>grid_search</code>，来储存<code>estimator = classifier</code> <code>param_grid = parameters</code> <code>scoring = &#39;accuracy&#39;</code> <code>cv = 10</code>，包含了classifier、参数dict、评分指标scoring metric和K-fold cross validation</li>
<li><code>grid_search</code>对象拟合训练集 - 用<code>.fit()</code></li>
<li>定义两个新变量存储参数最优选<code>best_parameters</code>和模型最优准确率<code>best_accuracy</code></li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Tuning the ANN</span></span><br><span class="line"><span class="keyword">from</span> keras.wrappers.scikit_learn <span class="keyword">import</span> KerasClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build_classifier</span> (optimizer):</span><br><span class="line">    </span><br><span class="line">    classifier = Sequential()</span><br><span class="line">    classifier.add(Dense(activation = <span class="string">&quot;relu&quot;</span>, units = <span class="number">6</span>, kernel_initializer = <span class="string">&quot;uniform&quot;</span>, input_dim = <span class="number">11</span>))</span><br><span class="line">    classifier.add(Dense(activation = <span class="string">&quot;relu&quot;</span>, units = <span class="number">6</span>, kernel_initializer = <span class="string">&quot;uniform&quot;</span>))</span><br><span class="line">    classifier.add(Dense(activation = <span class="string">&quot;sigmoid&quot;</span>, units = <span class="number">1</span>, kernel_initializer = <span class="string">&quot;uniform&quot;</span>))</span><br><span class="line">    classifier.<span class="built_in">compile</span>(optimizer = optimizer, loss = <span class="string">&#x27;binary_crossentropy&#x27;</span>, metrics = [<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> classifier</span><br><span class="line"></span><br><span class="line">classifier = KerasClassifier(build_fn = build_classifier)</span><br><span class="line">parameters = &#123;<span class="string">&#x27;batch_size&#x27;</span>:[<span class="number">25</span>, <span class="number">32</span>], </span><br><span class="line">              <span class="string">&#x27;nb_epoch&#x27;</span>:[<span class="number">100</span>, <span class="number">200</span>], </span><br><span class="line">              <span class="string">&#x27;optimizer&#x27;</span>: [<span class="string">&#x27;adam&#x27;</span>, <span class="string">&#x27;rmsprop&#x27;</span>]&#125;</span><br><span class="line"></span><br><span class="line">grid_search = GridSearchCV(estimator = classifier, </span><br><span class="line">                           param_grid = parameters,</span><br><span class="line">                           scoring = <span class="string">&#x27;accuracy&#x27;</span>,</span><br><span class="line">                           cv = <span class="number">10</span>)</span><br><span class="line">grid_search = grid_search.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">best_parameters = grid_search.best_params_</span><br><span class="line">best_accuracy = grid_search.best_score_</span><br></pre></td></tr></table></figure>

</div><div class="tags"><a href="/tags/DL/"><i class="fa fa-tag"></i>DL</a></div><div class="post-nav"><a class="pre" href="/2022/02/23/Web-Development-Tips/">Web Development and Web Design Tips</a><a class="next" href="/2022/02/21/Data%20preprocessing/">Data preprocessing</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://example.com"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> Categories</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/DL/">DL</a><span class="category-list-count">5</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/DL/ANN/">ANN</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/DL/CNN/">CNN</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/ML/">ML</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Web-Development/">Web Development</a><span class="category-list-count">3</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"><a href="/tags/DL/" style="font-size: 15px;">DL</a> <a href="/tags/Web/" style="font-size: 15px;">Web</a> <a href="/tags/CSS/" style="font-size: 15px;">CSS</a> <a href="/tags/ML/" style="font-size: 15px;">ML</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> Recent</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2022/02/25/CNN-Intuition/">CNN Intuition</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/02/23/Web-Development-Tips/">Web Development and Web Design Tips</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/02/22/ANN-Performance-and-Tuning/">ANN Performance and Tuning</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/02/21/Data%20preprocessing/">Data preprocessing</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/02/21/ANN%20Building/">ANN Building</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/02/20/DL-ANN/">ANN Intuition</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/02/20/DL/">Deep Learning Basic Concepts</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/02/20/Bootstrap5%20Notes/">Bootstrap5 Notes</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/02/19/My-first-Blog/">My first Blog</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/02/19/CSS%20Note/">CSS Notes</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> Links</i></div><ul></ul><a href="https://www.linkedin.com/in/vega-huang" title="LinkedIn" target="_blank">LinkedIn</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2022 <a href="/." rel="nofollow">Vega's Blog.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//cdn.jsdelivr.net/gh/fancyapps/fancybox/dist/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=1.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox/dist/jquery.fancybox.min.css"><script type="text/javascript" src="/js/copycode.js" successtext="Copy Successed!"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=1.0.0"></script></div></body></html>